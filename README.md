# ðŸ“Œ HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals

Arxiv: https://arxiv.org/pdf/2507.13318? (Findings of EMNLP2025) 

---

## ðŸ“– Introduction
**HapticCap** is a multimodal dataset and benchmark task designed for understanding **user experience of vibration-based haptic signals**.  
It provides a new resource for research at the intersection of **haptics, text, and multimodal learning**.

---

## ðŸ“‚ Dataset
- **Modality**: Vibration haptic signals, paired with textual annotations  
- **Textual Annotations**:  
  - Sensory: 
  - Emotional:
  - Associative:
- **Format**: Signals stored as time-series data; annotations in JSON with haptic signal ID  
- **Scale**: 

---

Google drive:

Haptic Vibration Signals:

Human Descriptions:


## ðŸ§© Tasks
- Haptic-caption retrieval

- Training set:

- Valid set:

- Test set:

## ðŸ§© Models



---

## ðŸš€ Resource:







